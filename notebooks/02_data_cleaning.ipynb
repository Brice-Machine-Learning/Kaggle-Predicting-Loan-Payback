{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Kaggle: Predict Loan Payback ‚Äî Data Cleaning\n",
    "\n",
    "**Notebook:** `02_data_cleaning.ipynb`\n",
    "**Author:** Brice Nelson\n",
    "**Organization:** Kaggle Series | Brice Machine Learning Projects\n",
    "**Date Created:** November 2, 2025\n",
    "**Last Updated:** November 15, 2025\n",
    "\n",
    "---\n",
    "\n",
    "## üß≠ Purpose\n",
    "\n",
    "This notebook performs **data cleaning and validation** for the Kaggle *Predict Loan Payback* dataset.\n",
    "The focus is on ensuring the **train** and **test** datasets are structurally aligned and free of inconsistencies prior to feature engineering and model training.\n",
    "\n",
    "### **Objectives**\n",
    "1. Load and inspect both train and test datasets.\n",
    "2. Validate schema consistency (columns, dtypes, and shapes).\n",
    "3. Identify and address any missing, duplicated, or outlier values.\n",
    "4. Standardize formatting across categorical and numeric fields.\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Dataset Comparison Overview\n",
    "\n",
    "Before applying cleaning operations, it is essential to verify that both datasets share compatible structures.\n",
    "The following checks confirm that column names, data types, and row counts align as expected.\n"
   ],
   "id": "63a245cb7bce8468"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Libraries",
   "id": "1f389583a47024c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T22:43:57.649878Z",
     "start_time": "2025-11-15T22:43:57.644477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n"
   ],
   "id": "dc4b5898cace7b55",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T21:23:48.889330Z",
     "start_time": "2025-11-15T21:23:47.933280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# üîç Train vs Test Structure Validation\n",
    "# ============================================================\n",
    "\n",
    "# Load datasets\n",
    "train_path = \"../data/raw/train.csv\"\n",
    "test_path = \"../data/raw/test.csv\"\n",
    "\n",
    "loan_train_df = pd.read_csv(train_path)\n",
    "loan_test_df = pd.read_csv(test_path)\n",
    "\n",
    "# Basic shape and info comparison\n",
    "print(f\"Train Shape: {loan_train_df.shape}\")\n",
    "print(f\"Test Shape:  {loan_test_df.shape}\\n\")\n",
    "\n",
    "print(\"Train Columns:\", loan_train_df.columns.tolist())\n",
    "print(\"Test Columns:\", loan_test_df.columns.tolist())\n",
    "\n",
    "# Define known target column(s)\n",
    "target_cols = {\"loan_paid_back\"}\n",
    "\n",
    "# Check for any column mismatches\n",
    "train_only_cols = set(loan_train_df.columns) - set(loan_test_df.columns) - target_cols\n",
    "test_only_cols = set(loan_test_df.columns) - set(loan_train_df.columns)\n",
    "\n",
    "if train_only_cols or test_only_cols:\n",
    "    print(\"\\n‚ö†Ô∏è Column mismatches detected:\")\n",
    "    if train_only_cols:\n",
    "        print(\"Columns only in train (excluding target):\", train_only_cols)\n",
    "    if test_only_cols:\n",
    "        print(\"Columns only in test:\", test_only_cols)\n",
    "else:\n",
    "    print(\"\\n‚úÖ Train and test datasets have matching columns (except for target variable).\")\n",
    "\n",
    "# Quick dtype consistency check (only for common columns)\n",
    "common_cols = loan_train_df.columns.intersection(loan_test_df.columns)\n",
    "dtype_diff = loan_train_df[common_cols].dtypes != loan_test_df[common_cols].dtypes\n",
    "\n",
    "if dtype_diff.any():\n",
    "    print(\"\\n‚ö†Ô∏è Data type mismatches found in the following columns:\")\n",
    "    print(loan_train_df[common_cols].dtypes[dtype_diff])\n",
    "else:\n",
    "    print(\"\\n‚úÖ Data types are consistent across train and test datasets.\")\n",
    "\n"
   ],
   "id": "a04f5e375593f243",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (593994, 13)\n",
      "Test Shape:  (254569, 12)\n",
      "\n",
      "Train Columns: ['id', 'annual_income', 'debt_to_income_ratio', 'credit_score', 'loan_amount', 'interest_rate', 'gender', 'marital_status', 'education_level', 'employment_status', 'loan_purpose', 'grade_subgrade', 'loan_paid_back']\n",
      "Test Columns: ['id', 'annual_income', 'debt_to_income_ratio', 'credit_score', 'loan_amount', 'interest_rate', 'gender', 'marital_status', 'education_level', 'employment_status', 'loan_purpose', 'grade_subgrade']\n",
      "\n",
      "‚úÖ Train and test datasets have matching columns (except for target variable).\n",
      "\n",
      "‚úÖ Data types are consistent across train and test datasets.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T21:23:51.069643Z",
     "start_time": "2025-11-15T21:23:50.955189Z"
    }
   },
   "cell_type": "code",
   "source": "loan_train_df.info()",
   "id": "362fbc5206a75e6b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 593994 entries, 0 to 593993\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   id                    593994 non-null  int64  \n",
      " 1   annual_income         593994 non-null  float64\n",
      " 2   debt_to_income_ratio  593994 non-null  float64\n",
      " 3   credit_score          593994 non-null  int64  \n",
      " 4   loan_amount           593994 non-null  float64\n",
      " 5   interest_rate         593994 non-null  float64\n",
      " 6   gender                593994 non-null  object \n",
      " 7   marital_status        593994 non-null  object \n",
      " 8   education_level       593994 non-null  object \n",
      " 9   employment_status     593994 non-null  object \n",
      " 10  loan_purpose          593994 non-null  object \n",
      " 11  grade_subgrade        593994 non-null  object \n",
      " 12  loan_paid_back        593994 non-null  float64\n",
      "dtypes: float64(5), int64(2), object(6)\n",
      "memory usage: 58.9+ MB\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Categorical Columns\n",
    "\n",
    "| Column           | Type of Encoding | # of Categories          | 1     | 2        | 3             | 4         | 5        | 6     | 7     | 8     |\n",
    "|------------------|------------------|-----------------|-------|----------|---------------|-----------|----------|-------|-------|-------|\n",
    "| gender           | One Hot Encoding | 3               | male                     | female   | other         |           |          |\n",
    "| marital_status   | One Hot Encoding | 4               | single                   | married  | divorced      | widowed   |          |\n",
    "| education_level  | One Hot Encoding | 5               | high_school              | bachelor  | master  | phd       | other    |\n",
    "| employment_status| One Hot Encoding | 5               | employed                 | unemployed| self_employed | retired   | student  |\n",
    "| loan_purpose     | One Hot Encoding | 8               | home                     | debt_consolidation | car           | education | business | medical | vacation | other |\n",
    "\n"
   ],
   "id": "f3fd500fba93a5e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Confirm Missing Data",
   "id": "df39a7691d79104a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T21:23:55.392349Z",
     "start_time": "2025-11-15T21:23:55.280833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "missing_data = pd.DataFrame({'Total Missing':loan_train_df.isnull().sum()})\n",
    "if missing_data['Total Missing'].any():\n",
    "    print(missing_data)\n",
    "else:\n",
    "    print('Data contains no null values')"
   ],
   "id": "4b28d09b51397598",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data contains no null values\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## One Hot Encoding vs. Ordinal Encoding\n",
    "* Ordinal Encoding ranks, One Hot Encoding does not\n",
    "* One Hot Encoding is more interpretable\n",
    "* Ordinal Encoding cannot contain noise in the data (ie: other has no ranking in education_level and cannot interpet it)\n",
    "* One Hot Encoding can contain noise in the data (ie: other has a ranking in employment_status)\n",
    "* Data needs to be explored before makine the decision to use OHE vs OE"
   ],
   "id": "cfbaf1a0b3955cd9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T21:23:58.316842Z",
     "start_time": "2025-11-15T21:23:58.278977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Explore `other` in `education_level`.  Can `other` be dropped\n",
    "loan_train_df['education_level'].value_counts(normalize=True)"
   ],
   "id": "c0d3bdb1339f99d7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education_level\n",
       "Bachelor's     0.470722\n",
       "High School    0.309081\n",
       "Master's       0.156731\n",
       "Other          0.044911\n",
       "PhD            0.018556\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### One Hot Encoding vs Ordinal Encoding Decision\n",
    "When preparing categorical features, a natural question arises:\n",
    "Should the variable be encoded as ordinal (ranked) or one-hot (unordered)?\n",
    "\n",
    "For categories that naturally follow a progression (e.g., high_school < bachelor < master < phd), ordinal encoding can make sense ‚Äî but only if all categories fit cleanly into that ranking.\n",
    "Before deciding, it‚Äôs important to look at the distribution of categories, especially any catch-all or ambiguous labels such as `Other`.\n",
    "\n",
    "| % of dataset | Typical action          | Rationale                          |\n",
    "| ------------ | ----------------------- | ---------------------------------- |\n",
    "| < 0.1%       | Drop freely             | Random noise, typo bucket          |\n",
    "| < 0.5%       | Drop if needed          | Still small enough                 |\n",
    "| 0.5%‚Äì1%      | Be cautious             | Dropping can distort distributions |\n",
    "| 1%‚Äì2%        | Rarely drop             | That‚Äôs meaningful population       |\n",
    "| 4%‚Äì5%        | **Never drop**          | This is a real category            |\n",
    "| >5%          | Treat as major category | Keep, understand, encode properly  |\n",
    "\n",
    "**Applying This to education_level**\n",
    "\n",
    "* The `Other` category in the training dataset accounts for 4.49% of all observations ‚Äî roughly 1 in 20 data points.\n",
    "* A category this large cannot be discarded without introducing bias or removing meaningful structure from the data.\n",
    "* Because education_level contains a catch-all `Other` bucket that does not fit cleanly into an ordered hierarchy, ordinal encoding would create an artificial ranking and inject false relationships.\n",
    "\n",
    "**Final Decision**\n",
    "\n",
    "* Use One-Hot Encoding for education_level.\n",
    "* This preserves all information, avoids incorrect ordinal assumptions, and reflects real-world feature engineering practice."
   ],
   "id": "71c921dddfbff34b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Ordinal Encoding\n",
    "The dataset includes a categorical variable called grade_subgrade, which represents a lender‚Äôs internal credit risk tier assigned to each loan applicant. This system is inherently ordinal:\n",
    "\n",
    "* The letter grade (A‚ÄìG) indicates the overall credit quality, where A is the lowest-risk tier and G is the highest-risk tier.\n",
    "* The subgrade (1‚Äì5) provides a finer ranking within each grade, e.g., A1 is better than A5, and B1 is better than B5.\n",
    "\n",
    "Because both components follow a strict, meaningful order, they should not be one-hot encoded. Instead:\n",
    "\n",
    "1. Split the combined string (grade_subgrade) into two columns:\n",
    "    * `grade`: first character (A‚ÄìG)\n",
    "    * `subgrade`: numeric rating within that grade (1‚Äì5)\n",
    "\n",
    "2. Encode each component using ordinal encoding, preserving the lender‚Äôs risk hierarchy:\n",
    "    * `grade`: A=1, B=2, ‚Ä¶ G=7\n",
    "    * `subgrade`: already numeric, use directly as an ordered variable\n",
    "\n",
    "This approach maintains the underlying credit-risk structure and avoids losing valuable predictive signal."
   ],
   "id": "45a7940529fdce52"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T21:24:10.535444Z",
     "start_time": "2025-11-15T21:24:10.106485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Ordinal Encoding for grade_subgrade ---\n",
    "# This version is safe to run multiple times without KeyErrors.\n",
    "\n",
    "# Split only if column exists\n",
    "if 'grade_subgrade' in loan_train_df.columns:\n",
    "\n",
    "    # Extract grade (Letter) and subgrade (Digit)\n",
    "    loan_train_df['grade'] = loan_train_df['grade_subgrade'].str[0]\n",
    "    loan_train_df['subgrade'] = loan_train_df['grade_subgrade'].str[1].astype(int)\n",
    "\n",
    "    loan_test_df['grade'] = loan_test_df['grade_subgrade'].str[0]\n",
    "    loan_test_df['subgrade'] = loan_test_df['grade_subgrade'].str[1].astype(int)\n",
    "\n",
    "    # Drop the original combined column\n",
    "    loan_train_df = loan_train_df.drop(columns=['grade_subgrade'])\n",
    "    loan_test_df = loan_test_df.drop(columns=['grade_subgrade'])\n",
    "\n",
    "# Ordinal encoding mapping\n",
    "grade_mapping = {'A':1, 'B':2, 'C':3, 'D':4, 'E':5, 'F':6, 'G':7}\n",
    "\n",
    "# Map grade values (safe even if it already exists)\n",
    "loan_train_df['grade'] = loan_train_df['grade'].map(grade_mapping)\n",
    "loan_test_df['grade'] = loan_test_df['grade'].map(grade_mapping)\n",
    "\n",
    "# sanity print\n",
    "print(loan_train_df\n",
    "      [['grade', 'subgrade']].head())\n"
   ],
   "id": "a6cf99723cc0ed20",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   grade  subgrade\n",
      "0      3         3\n",
      "1      4         3\n",
      "2      3         5\n",
      "3      6         1\n",
      "4      4         1\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T21:26:13.619361Z",
     "start_time": "2025-11-15T21:26:12.651580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- One-Hot Encoding for categorical columns (SAFE VERSION) ---\n",
    "\n",
    "# Define categorical columns\n",
    "cat_cols = [\n",
    "    \"gender\",\n",
    "    \"marital_status\",\n",
    "    \"education_level\",\n",
    "    \"employment_status\",\n",
    "    \"loan_purpose\"\n",
    "]\n",
    "\n",
    "# Only attempt encoding if ALL columns exist\n",
    "missing_columns = [col for col in cat_cols if col not in loan_train_df.columns]\n",
    "if missing_columns:\n",
    "    raise KeyError(f\"The following categorical columns are missing and cannot be encoded: {missing_columns}\")\n",
    "\n",
    "# Combine for fitting (avoids mismatched categories)\n",
    "combined_cat_data = pd.concat([loan_train_df[cat_cols], loan_test_df[cat_cols]], axis=0)\n",
    "\n",
    "# Create encoder\n",
    "ohe = OneHotEncoder(\n",
    "    handle_unknown=\"ignore\",\n",
    "    sparse_output=False\n",
    ")\n",
    "\n",
    "# Fit on combined\n",
    "ohe.fit(combined_cat_data)\n",
    "\n",
    "# Transform train/test\n",
    "train_ohe = ohe.transform(loan_train_df[cat_cols])\n",
    "test_ohe = ohe.transform(loan_test_df[cat_cols])\n",
    "\n",
    "# OHE feature names\n",
    "ohe_cols = ohe.get_feature_names_out(cat_cols)\n",
    "\n",
    "# Convert to DataFrames (safe ‚Äî does not modify original)\n",
    "loan_train_ohe_df = pd.DataFrame(train_ohe, columns=ohe_cols, index=loan_train_df.index)\n",
    "loan_test_ohe_df = pd.DataFrame(test_ohe, columns=ohe_cols, index=loan_test_df.index)\n",
    "\n",
    "print(\"OHE encoding complete. Encoded DataFrame shapes:\")\n",
    "print(\"Train OHE:\", loan_train_ohe_df.shape)\n",
    "print(\"Test OHE:\", loan_test_ohe_df.shape)\n",
    "\n",
    "\n"
   ],
   "id": "a35e76327ca69a66",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OHE encoding complete. Encoded DataFrame shapes:\n",
      "Train OHE: (593994, 25)\n",
      "Test OHE: (254569, 25)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T21:31:02.604975Z",
     "start_time": "2025-11-15T21:31:02.234622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Final merge for encoded features (SAFE VERSION) ---\n",
    "\n",
    "# Make copies so originals are never modified\n",
    "train_tmp = loan_train_df.copy()\n",
    "test_tmp = loan_test_df.copy()\n",
    "\n",
    "# Drop original categorical columns ONLY if they exist\n",
    "train_tmp = train_tmp.drop(columns=[col for col in cat_cols if col in train_tmp.columns])\n",
    "test_tmp = test_tmp.drop(columns=[col for col in cat_cols if col in test_tmp.columns])\n",
    "\n",
    "# Drop grade_subgrade if still present (safe)\n",
    "for col in ['grade_subgrade']:\n",
    "    if col in train_tmp.columns:\n",
    "        train_tmp = train_tmp.drop(columns=[col])\n",
    "    if col in test_tmp.columns:\n",
    "        test_tmp = test_tmp.drop(columns=[col])\n",
    "\n",
    "# Add OHE features (does not overlap with existing columns)\n",
    "loan_train_encoded = pd.concat([train_tmp, loan_train_ohe_df], axis=1)\n",
    "loan_test_encoded = pd.concat([test_tmp, loan_test_ohe_df], axis=1)\n",
    "\n",
    "print(\"Train encoded shape:\", loan_train_encoded.shape)\n",
    "print(\"Test encoded shape:\", loan_test_encoded.shape)\n",
    "\n"
   ],
   "id": "b86f414736221a2d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train encoded shape: (593994, 34)\n",
      "Test encoded shape: (254569, 33)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T21:31:06.026730Z",
     "start_time": "2025-11-15T21:31:06.022328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Sanity check: Ensure matching features between train and test ---\n",
    "\n",
    "train_cols = set(loan_train_encoded.columns) - {\"loan_paid_back\"}  # remove target\n",
    "test_cols = set(loan_test_encoded.columns)\n",
    "\n",
    "if train_cols != test_cols:\n",
    "    extra_in_train = train_cols - test_cols\n",
    "    extra_in_test = test_cols - train_cols\n",
    "\n",
    "    raise AssertionError(\n",
    "        f\"ERROR: Train and Test columns do NOT match!\\n\"\n",
    "        f\"Columns only in TRAIN: {extra_in_train}\\n\"\n",
    "        f\"Columns only in TEST : {extra_in_test}\"\n",
    "    )\n",
    "\n",
    "print(\"Column alignment check passed ‚Äî train/test feature sets match.\")\n",
    "\n"
   ],
   "id": "4afadf75f41757ca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column alignment check passed ‚Äî train/test feature sets match.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T22:01:51.631973Z",
     "start_time": "2025-11-15T22:01:51.520535Z"
    }
   },
   "cell_type": "code",
   "source": "loan_train_df.info()",
   "id": "ea266f5fd477e4b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 593994 entries, 0 to 593993\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   id                    593994 non-null  int64  \n",
      " 1   annual_income         593994 non-null  float64\n",
      " 2   debt_to_income_ratio  593994 non-null  float64\n",
      " 3   credit_score          593994 non-null  int64  \n",
      " 4   loan_amount           593994 non-null  float64\n",
      " 5   interest_rate         593994 non-null  float64\n",
      " 6   gender                593994 non-null  object \n",
      " 7   marital_status        593994 non-null  object \n",
      " 8   education_level       593994 non-null  object \n",
      " 9   employment_status     593994 non-null  object \n",
      " 10  loan_purpose          593994 non-null  object \n",
      " 11  loan_paid_back        593994 non-null  float64\n",
      " 12  grade                 593994 non-null  int64  \n",
      " 13  subgrade              593994 non-null  int64  \n",
      "dtypes: float64(5), int64(4), object(5)\n",
      "memory usage: 63.4+ MB\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T22:04:21.929195Z",
     "start_time": "2025-11-15T22:04:21.858568Z"
    }
   },
   "cell_type": "code",
   "source": "loan_train_encoded.info()\n",
   "id": "d3864704a298005a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 593994 entries, 0 to 593993\n",
      "Data columns (total 34 columns):\n",
      " #   Column                           Non-Null Count   Dtype  \n",
      "---  ------                           --------------   -----  \n",
      " 0   id                               593994 non-null  int64  \n",
      " 1   annual_income                    593994 non-null  float64\n",
      " 2   debt_to_income_ratio             593994 non-null  float64\n",
      " 3   credit_score                     593994 non-null  int64  \n",
      " 4   loan_amount                      593994 non-null  float64\n",
      " 5   interest_rate                    593994 non-null  float64\n",
      " 6   loan_paid_back                   593994 non-null  float64\n",
      " 7   grade                            593994 non-null  int64  \n",
      " 8   subgrade                         593994 non-null  int64  \n",
      " 9   gender_Female                    593994 non-null  float64\n",
      " 10  gender_Male                      593994 non-null  float64\n",
      " 11  gender_Other                     593994 non-null  float64\n",
      " 12  marital_status_Divorced          593994 non-null  float64\n",
      " 13  marital_status_Married           593994 non-null  float64\n",
      " 14  marital_status_Single            593994 non-null  float64\n",
      " 15  marital_status_Widowed           593994 non-null  float64\n",
      " 16  education_level_Bachelor's       593994 non-null  float64\n",
      " 17  education_level_High School      593994 non-null  float64\n",
      " 18  education_level_Master's         593994 non-null  float64\n",
      " 19  education_level_Other            593994 non-null  float64\n",
      " 20  education_level_PhD              593994 non-null  float64\n",
      " 21  employment_status_Employed       593994 non-null  float64\n",
      " 22  employment_status_Retired        593994 non-null  float64\n",
      " 23  employment_status_Self-employed  593994 non-null  float64\n",
      " 24  employment_status_Student        593994 non-null  float64\n",
      " 25  employment_status_Unemployed     593994 non-null  float64\n",
      " 26  loan_purpose_Business            593994 non-null  float64\n",
      " 27  loan_purpose_Car                 593994 non-null  float64\n",
      " 28  loan_purpose_Debt consolidation  593994 non-null  float64\n",
      " 29  loan_purpose_Education           593994 non-null  float64\n",
      " 30  loan_purpose_Home                593994 non-null  float64\n",
      " 31  loan_purpose_Medical             593994 non-null  float64\n",
      " 32  loan_purpose_Other               593994 non-null  float64\n",
      " 33  loan_purpose_Vacation            593994 non-null  float64\n",
      "dtypes: float64(30), int64(4)\n",
      "memory usage: 154.1 MB\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T22:05:59.119848Z",
     "start_time": "2025-11-15T22:05:59.103131Z"
    }
   },
   "cell_type": "code",
   "source": "loan_train_encoded.head()\n",
   "id": "1fe9d389a49ef9e4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   id  annual_income  debt_to_income_ratio  credit_score  loan_amount  \\\n",
       "0   0       29367.99                 0.084           736      2528.42   \n",
       "1   1       22108.02                 0.166           636      4593.10   \n",
       "2   2       49566.20                 0.097           694     17005.15   \n",
       "3   3       46858.25                 0.065           533      4682.48   \n",
       "4   4       25496.70                 0.053           665     12184.43   \n",
       "\n",
       "   interest_rate  loan_paid_back  grade  subgrade  gender_Female  ...  \\\n",
       "0          13.67             1.0      3         3            1.0  ...   \n",
       "1          12.92             0.0      4         3            0.0  ...   \n",
       "2           9.76             1.0      3         5            0.0  ...   \n",
       "3          16.10             1.0      6         1            1.0  ...   \n",
       "4          10.21             1.0      4         1            0.0  ...   \n",
       "\n",
       "   employment_status_Student  employment_status_Unemployed  \\\n",
       "0                        0.0                           0.0   \n",
       "1                        0.0                           0.0   \n",
       "2                        0.0                           0.0   \n",
       "3                        0.0                           0.0   \n",
       "4                        0.0                           0.0   \n",
       "\n",
       "   loan_purpose_Business  loan_purpose_Car  loan_purpose_Debt consolidation  \\\n",
       "0                    0.0               0.0                              0.0   \n",
       "1                    0.0               0.0                              1.0   \n",
       "2                    0.0               0.0                              1.0   \n",
       "3                    0.0               0.0                              1.0   \n",
       "4                    0.0               0.0                              0.0   \n",
       "\n",
       "   loan_purpose_Education  loan_purpose_Home  loan_purpose_Medical  \\\n",
       "0                     0.0                0.0                   0.0   \n",
       "1                     0.0                0.0                   0.0   \n",
       "2                     0.0                0.0                   0.0   \n",
       "3                     0.0                0.0                   0.0   \n",
       "4                     0.0                0.0                   0.0   \n",
       "\n",
       "   loan_purpose_Other  loan_purpose_Vacation  \n",
       "0                 1.0                    0.0  \n",
       "1                 0.0                    0.0  \n",
       "2                 0.0                    0.0  \n",
       "3                 0.0                    0.0  \n",
       "4                 1.0                    0.0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>debt_to_income_ratio</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>loan_paid_back</th>\n",
       "      <th>grade</th>\n",
       "      <th>subgrade</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>...</th>\n",
       "      <th>employment_status_Student</th>\n",
       "      <th>employment_status_Unemployed</th>\n",
       "      <th>loan_purpose_Business</th>\n",
       "      <th>loan_purpose_Car</th>\n",
       "      <th>loan_purpose_Debt consolidation</th>\n",
       "      <th>loan_purpose_Education</th>\n",
       "      <th>loan_purpose_Home</th>\n",
       "      <th>loan_purpose_Medical</th>\n",
       "      <th>loan_purpose_Other</th>\n",
       "      <th>loan_purpose_Vacation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>29367.99</td>\n",
       "      <td>0.084</td>\n",
       "      <td>736</td>\n",
       "      <td>2528.42</td>\n",
       "      <td>13.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22108.02</td>\n",
       "      <td>0.166</td>\n",
       "      <td>636</td>\n",
       "      <td>4593.10</td>\n",
       "      <td>12.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>49566.20</td>\n",
       "      <td>0.097</td>\n",
       "      <td>694</td>\n",
       "      <td>17005.15</td>\n",
       "      <td>9.76</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>46858.25</td>\n",
       "      <td>0.065</td>\n",
       "      <td>533</td>\n",
       "      <td>4682.48</td>\n",
       "      <td>16.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>25496.70</td>\n",
       "      <td>0.053</td>\n",
       "      <td>665</td>\n",
       "      <td>12184.43</td>\n",
       "      <td>10.21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 34 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üßÆ Scaling Numeric Features\n",
    "\n",
    "## Why Scaling Is Necessary\n",
    "Many machine learning algorithms are sensitive to differences in feature scales. In our dataset, numeric variables span very different ranges:\n",
    "\n",
    "- **loan_amount** ranges from a few thousand dollars to tens of thousands\n",
    "- **interest_rate** ranges from roughly 5‚Äì20%\n",
    "- **credit_score** ranges from 300‚Äì850\n",
    "- **debt_to_income_ratio** ranges from 0.0‚Äì1.0\n",
    "\n",
    "Without scaling, models such as:\n",
    "\n",
    "- Logistic Regression\n",
    "- Linear/ElasticNet models\n",
    "- Support Vector Machines\n",
    "- Neural Networks\n",
    "- K-Nearest Neighbors\n",
    "\n",
    "may unintentionally give more weight to large-magnitude features simply because of their scale, not because they are more predictive.\n",
    "\n",
    "Tree-based models (Random Forest, XGBoost, LightGBM, CatBoost) are scale-invariant, but scaling does **not hurt** them and keeps a unified preprocessing pipeline across all model types.\n",
    "\n",
    "---\n",
    "\n",
    "## Features Selected for Scaling\n",
    "We scale the following numeric features:\n",
    "\n",
    "- `annual_income`\n",
    "- `debt_to_income_ratio`\n",
    "- `credit_score`\n",
    "- `loan_amount`\n",
    "- `interest_rate`\n",
    "- `grade` (ordinal)\n",
    "- `subgrade` (ordinal)\n",
    "\n",
    "One-Hot Encoded categorical variables are **not scaled** because:\n",
    "\n",
    "- They are already in a consistent 0/1 range\n",
    "- Scaling them provides no modeling benefit\n",
    "- It can distort their interpretation\n",
    "\n",
    "---\n",
    "\n",
    "## How We Scale\n",
    "We use **StandardScaler**, which transforms each numeric column using:\n",
    "\n",
    "$$\n",
    "z = \\frac{x - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "This transformation ensures:\n",
    "\n",
    "- Mean = 0\n",
    "- Standard deviation = 1\n",
    "- Faster gradient-based optimization\n",
    "- More stable coefficients for linear models\n",
    "- Better numerical conditioning for SVM/NN models\n",
    "\n",
    "---\n",
    "\n",
    "## Avoiding Data Leakage\n",
    "To preserve model integrity, the scaler is:\n",
    "\n",
    "1. **Fit on the training data only**, then\n",
    "2. **Applied to both train and test sets**\n",
    "\n",
    "This prevents the model from ‚Äúseeing‚Äù test-set information during preprocessing.\n",
    "\n",
    "---\n",
    "\n",
    "## Output DataFrames\n",
    "After scaling, we produce:\n",
    "\n",
    "- `loan_train_scaled` ‚Üí fully encoded + scaled training data\n",
    "- `loan_test_scaled` ‚Üí fully encoded + scaled test data\n",
    "\n",
    "These DataFrames:\n",
    "\n",
    "- Contain only numeric features\n",
    "- Have no raw object/string columns\n",
    "- Include all OHE and ordinal encodings\n",
    "- Are standardized and ready for feature engineering + modeling\n"
   ],
   "id": "5970cb7fd341baa2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T22:34:40.903646Z",
     "start_time": "2025-11-15T22:34:40.150320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Scale Numeric Features (SAFE IMPLEMENTATION) ---\n",
    "\n",
    "# Columns to scale\n",
    "numeric_cols = [\n",
    "    \"annual_income\",\n",
    "    \"debt_to_income_ratio\",\n",
    "    \"credit_score\",\n",
    "    \"loan_amount\",\n",
    "    \"interest_rate\",\n",
    "    \"grade\",\n",
    "    \"subgrade\",\n",
    "]\n",
    "\n",
    "# Create scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create copies so original encoded data stays clean\n",
    "loan_train_scaled = loan_train_encoded.copy()\n",
    "loan_test_scaled = loan_test_encoded.copy()\n",
    "\n",
    "# Ensure columns exist before scaling\n",
    "missing_cols = [col for col in numeric_cols if col not in loan_train_scaled.columns]\n",
    "if missing_cols:\n",
    "    raise KeyError(f\"Cannot scale. Missing columns: {missing_cols}\")\n",
    "\n",
    "# Fit on TRAIN, apply to TRAIN + TEST (avoid data leakage)\n",
    "loan_train_scaled[numeric_cols] = scaler.fit_transform(\n",
    "    loan_train_encoded[numeric_cols]\n",
    ")\n",
    "loan_test_scaled[numeric_cols] = scaler.transform(\n",
    "    loan_test_encoded[numeric_cols]\n",
    ")\n",
    "\n",
    "print(\"Scaling complete.\")\n",
    "print(\"Train scaled shape:\", loan_train_scaled.shape)\n",
    "print(\"Test scaled shape:\", loan_test_scaled.shape)\n"
   ],
   "id": "f0e5a0356cd69b0f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling complete.\n",
      "Train scaled shape: (593994, 34)\n",
      "Test scaled shape: (254569, 33)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T22:45:00.704372Z",
     "start_time": "2025-11-15T22:44:45.277662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Export processed datasets ---\n",
    "\n",
    "# Create processed directory if it doesn't exist\n",
    "processed_path = \"../data/processed\"\n",
    "os.makedirs(processed_path, exist_ok=True)\n",
    "\n",
    "# File paths\n",
    "train_path = os.path.join(processed_path, \"loan_train_scaled.csv\")\n",
    "test_path = os.path.join(processed_path, \"loan_test_scaled.csv\")\n",
    "\n",
    "# Export\n",
    "loan_train_scaled.to_csv(train_path, index=False)\n",
    "loan_test_scaled.to_csv(test_path, index=False)\n",
    "\n",
    "print(\"Export complete:\")\n",
    "print(f\" - {train_path}\")\n",
    "print(f\" - {test_path}\")\n"
   ],
   "id": "8edd2af2dd3ab14c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export complete:\n",
      " - ../data/processed/loan_train_scaled.csv\n",
      " - ../data/processed/loan_test_scaled.csv\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ‚úÖ Summary: Data Cleaning & Preprocessing\n",
    "\n",
    "This notebook completed all core preprocessing steps required to transform the raw Kaggle loan dataset into a clean, numeric, model-ready form. The following tasks were performed:\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ 1. Ordinal Encoding: `grade_subgrade`\n",
    "The lender-provided credit tier (`grade_subgrade`) was split into:\n",
    "- `grade` (A‚ÄìG ‚Üí 1‚Äì7 ordinal scale)\n",
    "- `subgrade` (1‚Äì5 numeric)\n",
    "\n",
    "This preserves the inherent credit-risk ordering that lenders use when assigning borrower quality.\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ 2. One-Hot Encoding for Categorical Variables\n",
    "The following categorical fields were converted into numeric indicator features using `OneHotEncoder`:\n",
    "\n",
    "- `gender`\n",
    "- `marital_status`\n",
    "- `education_level`\n",
    "- `employment_status`\n",
    "- `loan_purpose`\n",
    "\n",
    "These features do **not** have meaningful ordinal structure, so OHE prevents the model from inferring false ordering.\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ 3. Train/Test Alignment\n",
    "To avoid mismatched columns between train and test:\n",
    "- OHE was fit on **combined** train + test categories\n",
    "- A validation check ensured both final matrices contain identical feature sets\n",
    "- This prevents unseen-category failures during inference\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ 4. Scaling Numeric Variables\n",
    "All numeric features were standardized using **StandardScaler**:\n",
    "\n",
    "$$\n",
    "z = \\frac{x - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "The following columns were scaled:\n",
    "\n",
    "- `annual_income`\n",
    "- `debt_to_income_ratio`\n",
    "- `credit_score`\n",
    "- `loan_amount`\n",
    "- `interest_rate`\n",
    "- `grade`\n",
    "- `subgrade`\n",
    "\n",
    "Scaling improves model stability for linear, SVM, and neural models while keeping tree models unaffected.\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ 5. Processed Dataset Export\n",
    "Final preprocessed matrices were saved to:\n",
    "\n"
   ],
   "id": "d020753ced56b9b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cd6302759ca8a3df"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
