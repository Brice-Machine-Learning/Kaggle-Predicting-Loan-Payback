{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Kaggle: Predict Loan Payback ‚Äî Data Cleaning\n",
    "\n",
    "**Notebook:** `02_data_cleaning.ipynb`\n",
    "**Author:** Brice Nelson\n",
    "**Organization:** Kaggle Series | Brice Machine Learning Projects\n",
    "**Date Created:** November 2, 2025\n",
    "**Last Updated:** November 2, 2025\n",
    "\n",
    "---\n",
    "\n",
    "## üß≠ Purpose\n",
    "\n",
    "This notebook performs **data cleaning and validation** for the Kaggle *Predict Loan Payback* dataset.\n",
    "The focus is on ensuring the **train** and **test** datasets are structurally aligned and free of inconsistencies prior to feature engineering and model training.\n",
    "\n",
    "### **Objectives**\n",
    "1. Load and inspect both train and test datasets.\n",
    "2. Validate schema consistency (columns, dtypes, and shapes).\n",
    "3. Identify and address any missing, duplicated, or outlier values.\n",
    "4. Standardize formatting across categorical and numeric fields.\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Dataset Comparison Overview\n",
    "\n",
    "Before applying cleaning operations, it is essential to verify that both datasets share compatible structures.\n",
    "The following checks confirm that column names, data types, and row counts align as expected.\n"
   ],
   "id": "63a245cb7bce8468"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Libraries",
   "id": "1f389583a47024c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T04:32:03.244291Z",
     "start_time": "2025-11-14T04:32:03.239350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ],
   "id": "dc4b5898cace7b55",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T04:33:25.227485Z",
     "start_time": "2025-11-14T04:33:23.829991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# üîç Train vs Test Structure Validation\n",
    "# ============================================================\n",
    "\n",
    "# Load datasets\n",
    "train_path = \"../data/raw/train.csv\"\n",
    "test_path = \"../data/raw/test.csv\"\n",
    "\n",
    "loan_train_df = pd.read_csv(train_path)\n",
    "loan_test_df = pd.read_csv(test_path)\n",
    "\n",
    "# Basic shape and info comparison\n",
    "print(f\"Train Shape: {loan_train_df.shape}\")\n",
    "print(f\"Test Shape:  {loan_test_df.shape}\\n\")\n",
    "\n",
    "print(\"Train Columns:\", loan_train_df.columns.tolist())\n",
    "print(\"Test Columns:\", loan_test_df.columns.tolist())\n",
    "\n",
    "# Define known target column(s)\n",
    "target_cols = {\"loan_paid_back\"}\n",
    "\n",
    "# Check for any column mismatches\n",
    "train_only_cols = set(loan_train_df.columns) - set(loan_test_df.columns) - target_cols\n",
    "test_only_cols = set(loan_test_df.columns) - set(loan_train_df.columns)\n",
    "\n",
    "if train_only_cols or test_only_cols:\n",
    "    print(\"\\n‚ö†Ô∏è Column mismatches detected:\")\n",
    "    if train_only_cols:\n",
    "        print(\"Columns only in train (excluding target):\", train_only_cols)\n",
    "    if test_only_cols:\n",
    "        print(\"Columns only in test:\", test_only_cols)\n",
    "else:\n",
    "    print(\"\\n‚úÖ Train and test datasets have matching columns (except for target variable).\")\n",
    "\n",
    "# Quick dtype consistency check (only for common columns)\n",
    "common_cols = loan_train_df.columns.intersection(loan_test_df.columns)\n",
    "dtype_diff = loan_train_df[common_cols].dtypes != loan_test_df[common_cols].dtypes\n",
    "\n",
    "if dtype_diff.any():\n",
    "    print(\"\\n‚ö†Ô∏è Data type mismatches found in the following columns:\")\n",
    "    print(loan_train_df[common_cols].dtypes[dtype_diff])\n",
    "else:\n",
    "    print(\"\\n‚úÖ Data types are consistent across train and test datasets.\")\n",
    "\n"
   ],
   "id": "a04f5e375593f243",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (593994, 13)\n",
      "Test Shape:  (254569, 12)\n",
      "\n",
      "Train Columns: ['id', 'annual_income', 'debt_to_income_ratio', 'credit_score', 'loan_amount', 'interest_rate', 'gender', 'marital_status', 'education_level', 'employment_status', 'loan_purpose', 'grade_subgrade', 'loan_paid_back']\n",
      "Test Columns: ['id', 'annual_income', 'debt_to_income_ratio', 'credit_score', 'loan_amount', 'interest_rate', 'gender', 'marital_status', 'education_level', 'employment_status', 'loan_purpose', 'grade_subgrade']\n",
      "\n",
      "‚úÖ Train and test datasets have matching columns (except for target variable).\n",
      "\n",
      "‚úÖ Data types are consistent across train and test datasets.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T04:33:30.174550Z",
     "start_time": "2025-11-14T04:33:29.845171Z"
    }
   },
   "cell_type": "code",
   "source": "loan_train_df.info()",
   "id": "362fbc5206a75e6b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 593994 entries, 0 to 593993\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   id                    593994 non-null  int64  \n",
      " 1   annual_income         593994 non-null  float64\n",
      " 2   debt_to_income_ratio  593994 non-null  float64\n",
      " 3   credit_score          593994 non-null  int64  \n",
      " 4   loan_amount           593994 non-null  float64\n",
      " 5   interest_rate         593994 non-null  float64\n",
      " 6   gender                593994 non-null  object \n",
      " 7   marital_status        593994 non-null  object \n",
      " 8   education_level       593994 non-null  object \n",
      " 9   employment_status     593994 non-null  object \n",
      " 10  loan_purpose          593994 non-null  object \n",
      " 11  grade_subgrade        593994 non-null  object \n",
      " 12  loan_paid_back        593994 non-null  float64\n",
      "dtypes: float64(5), int64(2), object(6)\n",
      "memory usage: 58.9+ MB\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Categorical Columns\n",
    "\n",
    "| Column           | # of Categories | 1     | 2        | 3             | 4         | 5        | 6     | 7     | 8     |\n",
    "|------------------|-----------------|-------|----------|---------------|-----------|----------|-------|-------|-------|\n",
    "| gender           | 3               | male  | female   | other         |           |          |\n",
    "| marital_status   | 4               | single | married  | divorced      | widowed   |          |\n",
    "| education_level  | 5               | high_school | bachelor  | master  | phd       | other    |\n",
    "| employment_status| 5               | employed | unemployed| self_employed | retired   | student  |\n",
    "| loan_purpose     | 8               | home  | debt_consolidation | car           | education | business | medical | vacation | other |\n",
    "\n"
   ],
   "id": "f3fd500fba93a5e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Confirm Missing Data",
   "id": "df39a7691d79104a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T05:31:43.702667Z",
     "start_time": "2025-11-14T05:31:43.446741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "missing_data = pd.DataFrame({'Total Missing':loan_train_df.isnull().sum()})\n",
    "if missing_data['Total Missing'].any():\n",
    "    print(missing_data)\n",
    "else:\n",
    "    print('Data contains no null values')"
   ],
   "id": "4b28d09b51397598",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data contains no null values\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hot Encoding Categorical Data",
   "id": "cfbaf1a0b3955cd9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c0d3bdb1339f99d7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
