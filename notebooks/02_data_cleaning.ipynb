{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Kaggle: Predict Loan Payback ‚Äî Data Cleaning\n",
    "\n",
    "**Notebook:** `02_data_cleaning.ipynb`\n",
    "**Author:** Brice Nelson\n",
    "**Organization:** Kaggle Series | Brice Machine Learning Projects\n",
    "**Date Created:** November 2, 2025\n",
    "**Last Updated:** November 2, 2025\n",
    "\n",
    "---\n",
    "\n",
    "## üß≠ Purpose\n",
    "\n",
    "This notebook performs **data cleaning and validation** for the Kaggle *Predict Loan Payback* dataset.\n",
    "The focus is on ensuring the **train** and **test** datasets are structurally aligned and free of inconsistencies prior to feature engineering and model training.\n",
    "\n",
    "### **Objectives**\n",
    "1. Load and inspect both train and test datasets.\n",
    "2. Validate schema consistency (columns, dtypes, and shapes).\n",
    "3. Identify and address any missing, duplicated, or outlier values.\n",
    "4. Standardize formatting across categorical and numeric fields.\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Dataset Comparison Overview\n",
    "\n",
    "Before applying cleaning operations, it is essential to verify that both datasets share compatible structures.\n",
    "The following checks confirm that column names, data types, and row counts align as expected.\n"
   ],
   "id": "63a245cb7bce8468"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Libraries",
   "id": "1f389583a47024c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T17:56:35.944639Z",
     "start_time": "2025-11-15T17:56:35.941884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ],
   "id": "dc4b5898cace7b55",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T17:31:50.034592Z",
     "start_time": "2025-11-15T17:31:48.955823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# üîç Train vs Test Structure Validation\n",
    "# ============================================================\n",
    "\n",
    "# Load datasets\n",
    "train_path = \"../data/raw/train.csv\"\n",
    "test_path = \"../data/raw/test.csv\"\n",
    "\n",
    "loan_train_df = pd.read_csv(train_path)\n",
    "loan_test_df = pd.read_csv(test_path)\n",
    "\n",
    "# Basic shape and info comparison\n",
    "print(f\"Train Shape: {loan_train_df.shape}\")\n",
    "print(f\"Test Shape:  {loan_test_df.shape}\\n\")\n",
    "\n",
    "print(\"Train Columns:\", loan_train_df.columns.tolist())\n",
    "print(\"Test Columns:\", loan_test_df.columns.tolist())\n",
    "\n",
    "# Define known target column(s)\n",
    "target_cols = {\"loan_paid_back\"}\n",
    "\n",
    "# Check for any column mismatches\n",
    "train_only_cols = set(loan_train_df.columns) - set(loan_test_df.columns) - target_cols\n",
    "test_only_cols = set(loan_test_df.columns) - set(loan_train_df.columns)\n",
    "\n",
    "if train_only_cols or test_only_cols:\n",
    "    print(\"\\n‚ö†Ô∏è Column mismatches detected:\")\n",
    "    if train_only_cols:\n",
    "        print(\"Columns only in train (excluding target):\", train_only_cols)\n",
    "    if test_only_cols:\n",
    "        print(\"Columns only in test:\", test_only_cols)\n",
    "else:\n",
    "    print(\"\\n‚úÖ Train and test datasets have matching columns (except for target variable).\")\n",
    "\n",
    "# Quick dtype consistency check (only for common columns)\n",
    "common_cols = loan_train_df.columns.intersection(loan_test_df.columns)\n",
    "dtype_diff = loan_train_df[common_cols].dtypes != loan_test_df[common_cols].dtypes\n",
    "\n",
    "if dtype_diff.any():\n",
    "    print(\"\\n‚ö†Ô∏è Data type mismatches found in the following columns:\")\n",
    "    print(loan_train_df[common_cols].dtypes[dtype_diff])\n",
    "else:\n",
    "    print(\"\\n‚úÖ Data types are consistent across train and test datasets.\")\n",
    "\n"
   ],
   "id": "a04f5e375593f243",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (593994, 13)\n",
      "Test Shape:  (254569, 12)\n",
      "\n",
      "Train Columns: ['id', 'annual_income', 'debt_to_income_ratio', 'credit_score', 'loan_amount', 'interest_rate', 'gender', 'marital_status', 'education_level', 'employment_status', 'loan_purpose', 'grade_subgrade', 'loan_paid_back']\n",
      "Test Columns: ['id', 'annual_income', 'debt_to_income_ratio', 'credit_score', 'loan_amount', 'interest_rate', 'gender', 'marital_status', 'education_level', 'employment_status', 'loan_purpose', 'grade_subgrade']\n",
      "\n",
      "‚úÖ Train and test datasets have matching columns (except for target variable).\n",
      "\n",
      "‚úÖ Data types are consistent across train and test datasets.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T17:31:58.618031Z",
     "start_time": "2025-11-15T17:31:58.485108Z"
    }
   },
   "cell_type": "code",
   "source": "loan_train_df.info()",
   "id": "362fbc5206a75e6b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 593994 entries, 0 to 593993\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   id                    593994 non-null  int64  \n",
      " 1   annual_income         593994 non-null  float64\n",
      " 2   debt_to_income_ratio  593994 non-null  float64\n",
      " 3   credit_score          593994 non-null  int64  \n",
      " 4   loan_amount           593994 non-null  float64\n",
      " 5   interest_rate         593994 non-null  float64\n",
      " 6   gender                593994 non-null  object \n",
      " 7   marital_status        593994 non-null  object \n",
      " 8   education_level       593994 non-null  object \n",
      " 9   employment_status     593994 non-null  object \n",
      " 10  loan_purpose          593994 non-null  object \n",
      " 11  grade_subgrade        593994 non-null  object \n",
      " 12  loan_paid_back        593994 non-null  float64\n",
      "dtypes: float64(5), int64(2), object(6)\n",
      "memory usage: 58.9+ MB\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Categorical Columns\n",
    "\n",
    "| Column           | Type of Encoding | # of Categories          | 1     | 2        | 3             | 4         | 5        | 6     | 7     | 8     |\n",
    "|------------------|------------------|-----------------|-------|----------|---------------|-----------|----------|-------|-------|-------|\n",
    "| gender           | One Hot Encoding | 3               | male                     | female   | other         |           |          |\n",
    "| marital_status   | One Hot Encoding | 4               | single                   | married  | divorced      | widowed   |          |\n",
    "| education_level  | One Hot Encoding | 5               | high_school              | bachelor  | master  | phd       | other    |\n",
    "| employment_status| One Hot Encoding | 5               | employed                 | unemployed| self_employed | retired   | student  |\n",
    "| loan_purpose     | One Hot Encoding | 8               | home                     | debt_consolidation | car           | education | business | medical | vacation | other |\n",
    "\n"
   ],
   "id": "f3fd500fba93a5e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Confirm Missing Data",
   "id": "df39a7691d79104a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T17:32:12.153233Z",
     "start_time": "2025-11-15T17:32:12.026715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "missing_data = pd.DataFrame({'Total Missing':loan_train_df.isnull().sum()})\n",
    "if missing_data['Total Missing'].any():\n",
    "    print(missing_data)\n",
    "else:\n",
    "    print('Data contains no null values')"
   ],
   "id": "4b28d09b51397598",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data contains no null values\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## One Hot Encoding vs. Ordinal Encoding\n",
    "* Ordinal Encoding ranks, One Hot Encoding does not\n",
    "* One Hot Encoding is more interpretable\n",
    "* Ordinal Encoding cannot contain noise in the data (ie: other has no ranking in education_level and cannot interpet it)\n",
    "* One Hot Encoding can contain noise in the data (ie: other has a ranking in employment_status)\n",
    "* Data needs to be explored before makine the decision to use OHE vs OE"
   ],
   "id": "cfbaf1a0b3955cd9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T18:03:10.993740Z",
     "start_time": "2025-11-15T18:03:10.935244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Explore `other` in `education_level`.  Can `other` be dropped\n",
    "loan_train_df['education_level'].value_counts(normalize=True)"
   ],
   "id": "c0d3bdb1339f99d7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education_level\n",
       "Bachelor's     0.470722\n",
       "High School    0.309081\n",
       "Master's       0.156731\n",
       "Other          0.044911\n",
       "PhD            0.018556\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### One Hot Encoding vs Ordinal Encoding Decision\n",
    "When preparing categorical features, a natural question arises:\n",
    "Should the variable be encoded as ordinal (ranked) or one-hot (unordered)?\n",
    "\n",
    "For categories that naturally follow a progression (e.g., high_school < bachelor < master < phd), ordinal encoding can make sense ‚Äî but only if all categories fit cleanly into that ranking.\n",
    "Before deciding, it‚Äôs important to look at the distribution of categories, especially any catch-all or ambiguous labels such as `Other`.\n",
    "\n",
    "| % of dataset | Typical action          | Rationale                          |\n",
    "| ------------ | ----------------------- | ---------------------------------- |\n",
    "| < 0.1%       | Drop freely             | Random noise, typo bucket          |\n",
    "| < 0.5%       | Drop if needed          | Still small enough                 |\n",
    "| 0.5%‚Äì1%      | Be cautious             | Dropping can distort distributions |\n",
    "| 1%‚Äì2%        | Rarely drop             | That‚Äôs meaningful population       |\n",
    "| 4%‚Äì5%        | **Never drop**          | This is a real category            |\n",
    "| >5%          | Treat as major category | Keep, understand, encode properly  |\n",
    "\n",
    "**Applying This to education_level**\n",
    "\n",
    "* The `Other` category in the training dataset accounts for 4.49% of all observations ‚Äî roughly 1 in 20 data points.\n",
    "* A category this large cannot be discarded without introducing bias or removing meaningful structure from the data.\n",
    "* Because education_level contains a catch-all `Other` bucket that does not fit cleanly into an ordered hierarchy, ordinal encoding would create an artificial ranking and inject false relationships.\n",
    "\n",
    "**Final Decision**\n",
    "\n",
    "* Use One-Hot Encoding for education_level.\n",
    "* This preserves all information, avoids incorrect ordinal assumptions, and reflects real-world feature engineering practice."
   ],
   "id": "71c921dddfbff34b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a6cf99723cc0ed20"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
