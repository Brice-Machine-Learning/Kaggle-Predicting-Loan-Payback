{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Kaggle: Predict Loan Payback ‚Äî Data Cleaning\n",
    "\n",
    "**Notebook:** `02_data_cleaning.ipynb`\n",
    "**Author:** Brice Nelson\n",
    "**Organization:** Kaggle Series | Brice Machine Learning Projects\n",
    "**Date Created:** November 2, 2025\n",
    "**Last Updated:** November 2, 2025\n",
    "\n",
    "---\n",
    "\n",
    "## üß≠ Purpose\n",
    "\n",
    "This notebook performs **data cleaning and validation** for the Kaggle *Predict Loan Payback* dataset.\n",
    "The focus is on ensuring the **train** and **test** datasets are structurally aligned and free of inconsistencies prior to feature engineering and model training.\n",
    "\n",
    "### **Objectives**\n",
    "1. Load and inspect both train and test datasets.\n",
    "2. Validate schema consistency (columns, dtypes, and shapes).\n",
    "3. Identify and address any missing, duplicated, or outlier values.\n",
    "4. Standardize formatting across categorical and numeric fields.\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Dataset Comparison Overview\n",
    "\n",
    "Before applying cleaning operations, it is essential to verify that both datasets share compatible structures.\n",
    "The following checks confirm that column names, data types, and row counts align as expected.\n"
   ],
   "id": "63a245cb7bce8468"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Libraries",
   "id": "1f389583a47024c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T21:23:45.021331Z",
     "start_time": "2025-11-15T21:23:44.956303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n"
   ],
   "id": "dc4b5898cace7b55",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T21:23:48.889330Z",
     "start_time": "2025-11-15T21:23:47.933280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# üîç Train vs Test Structure Validation\n",
    "# ============================================================\n",
    "\n",
    "# Load datasets\n",
    "train_path = \"../data/raw/train.csv\"\n",
    "test_path = \"../data/raw/test.csv\"\n",
    "\n",
    "loan_train_df = pd.read_csv(train_path)\n",
    "loan_test_df = pd.read_csv(test_path)\n",
    "\n",
    "# Basic shape and info comparison\n",
    "print(f\"Train Shape: {loan_train_df.shape}\")\n",
    "print(f\"Test Shape:  {loan_test_df.shape}\\n\")\n",
    "\n",
    "print(\"Train Columns:\", loan_train_df.columns.tolist())\n",
    "print(\"Test Columns:\", loan_test_df.columns.tolist())\n",
    "\n",
    "# Define known target column(s)\n",
    "target_cols = {\"loan_paid_back\"}\n",
    "\n",
    "# Check for any column mismatches\n",
    "train_only_cols = set(loan_train_df.columns) - set(loan_test_df.columns) - target_cols\n",
    "test_only_cols = set(loan_test_df.columns) - set(loan_train_df.columns)\n",
    "\n",
    "if train_only_cols or test_only_cols:\n",
    "    print(\"\\n‚ö†Ô∏è Column mismatches detected:\")\n",
    "    if train_only_cols:\n",
    "        print(\"Columns only in train (excluding target):\", train_only_cols)\n",
    "    if test_only_cols:\n",
    "        print(\"Columns only in test:\", test_only_cols)\n",
    "else:\n",
    "    print(\"\\n‚úÖ Train and test datasets have matching columns (except for target variable).\")\n",
    "\n",
    "# Quick dtype consistency check (only for common columns)\n",
    "common_cols = loan_train_df.columns.intersection(loan_test_df.columns)\n",
    "dtype_diff = loan_train_df[common_cols].dtypes != loan_test_df[common_cols].dtypes\n",
    "\n",
    "if dtype_diff.any():\n",
    "    print(\"\\n‚ö†Ô∏è Data type mismatches found in the following columns:\")\n",
    "    print(loan_train_df[common_cols].dtypes[dtype_diff])\n",
    "else:\n",
    "    print(\"\\n‚úÖ Data types are consistent across train and test datasets.\")\n",
    "\n"
   ],
   "id": "a04f5e375593f243",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (593994, 13)\n",
      "Test Shape:  (254569, 12)\n",
      "\n",
      "Train Columns: ['id', 'annual_income', 'debt_to_income_ratio', 'credit_score', 'loan_amount', 'interest_rate', 'gender', 'marital_status', 'education_level', 'employment_status', 'loan_purpose', 'grade_subgrade', 'loan_paid_back']\n",
      "Test Columns: ['id', 'annual_income', 'debt_to_income_ratio', 'credit_score', 'loan_amount', 'interest_rate', 'gender', 'marital_status', 'education_level', 'employment_status', 'loan_purpose', 'grade_subgrade']\n",
      "\n",
      "‚úÖ Train and test datasets have matching columns (except for target variable).\n",
      "\n",
      "‚úÖ Data types are consistent across train and test datasets.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T21:23:51.069643Z",
     "start_time": "2025-11-15T21:23:50.955189Z"
    }
   },
   "cell_type": "code",
   "source": "loan_train_df.info()",
   "id": "362fbc5206a75e6b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 593994 entries, 0 to 593993\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   id                    593994 non-null  int64  \n",
      " 1   annual_income         593994 non-null  float64\n",
      " 2   debt_to_income_ratio  593994 non-null  float64\n",
      " 3   credit_score          593994 non-null  int64  \n",
      " 4   loan_amount           593994 non-null  float64\n",
      " 5   interest_rate         593994 non-null  float64\n",
      " 6   gender                593994 non-null  object \n",
      " 7   marital_status        593994 non-null  object \n",
      " 8   education_level       593994 non-null  object \n",
      " 9   employment_status     593994 non-null  object \n",
      " 10  loan_purpose          593994 non-null  object \n",
      " 11  grade_subgrade        593994 non-null  object \n",
      " 12  loan_paid_back        593994 non-null  float64\n",
      "dtypes: float64(5), int64(2), object(6)\n",
      "memory usage: 58.9+ MB\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Categorical Columns\n",
    "\n",
    "| Column           | Type of Encoding | # of Categories          | 1     | 2        | 3             | 4         | 5        | 6     | 7     | 8     |\n",
    "|------------------|------------------|-----------------|-------|----------|---------------|-----------|----------|-------|-------|-------|\n",
    "| gender           | One Hot Encoding | 3               | male                     | female   | other         |           |          |\n",
    "| marital_status   | One Hot Encoding | 4               | single                   | married  | divorced      | widowed   |          |\n",
    "| education_level  | One Hot Encoding | 5               | high_school              | bachelor  | master  | phd       | other    |\n",
    "| employment_status| One Hot Encoding | 5               | employed                 | unemployed| self_employed | retired   | student  |\n",
    "| loan_purpose     | One Hot Encoding | 8               | home                     | debt_consolidation | car           | education | business | medical | vacation | other |\n",
    "\n"
   ],
   "id": "f3fd500fba93a5e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Confirm Missing Data",
   "id": "df39a7691d79104a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T21:23:55.392349Z",
     "start_time": "2025-11-15T21:23:55.280833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "missing_data = pd.DataFrame({'Total Missing':loan_train_df.isnull().sum()})\n",
    "if missing_data['Total Missing'].any():\n",
    "    print(missing_data)\n",
    "else:\n",
    "    print('Data contains no null values')"
   ],
   "id": "4b28d09b51397598",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data contains no null values\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## One Hot Encoding vs. Ordinal Encoding\n",
    "* Ordinal Encoding ranks, One Hot Encoding does not\n",
    "* One Hot Encoding is more interpretable\n",
    "* Ordinal Encoding cannot contain noise in the data (ie: other has no ranking in education_level and cannot interpet it)\n",
    "* One Hot Encoding can contain noise in the data (ie: other has a ranking in employment_status)\n",
    "* Data needs to be explored before makine the decision to use OHE vs OE"
   ],
   "id": "cfbaf1a0b3955cd9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T21:23:58.316842Z",
     "start_time": "2025-11-15T21:23:58.278977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Explore `other` in `education_level`.  Can `other` be dropped\n",
    "loan_train_df['education_level'].value_counts(normalize=True)"
   ],
   "id": "c0d3bdb1339f99d7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education_level\n",
       "Bachelor's     0.470722\n",
       "High School    0.309081\n",
       "Master's       0.156731\n",
       "Other          0.044911\n",
       "PhD            0.018556\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### One Hot Encoding vs Ordinal Encoding Decision\n",
    "When preparing categorical features, a natural question arises:\n",
    "Should the variable be encoded as ordinal (ranked) or one-hot (unordered)?\n",
    "\n",
    "For categories that naturally follow a progression (e.g., high_school < bachelor < master < phd), ordinal encoding can make sense ‚Äî but only if all categories fit cleanly into that ranking.\n",
    "Before deciding, it‚Äôs important to look at the distribution of categories, especially any catch-all or ambiguous labels such as `Other`.\n",
    "\n",
    "| % of dataset | Typical action          | Rationale                          |\n",
    "| ------------ | ----------------------- | ---------------------------------- |\n",
    "| < 0.1%       | Drop freely             | Random noise, typo bucket          |\n",
    "| < 0.5%       | Drop if needed          | Still small enough                 |\n",
    "| 0.5%‚Äì1%      | Be cautious             | Dropping can distort distributions |\n",
    "| 1%‚Äì2%        | Rarely drop             | That‚Äôs meaningful population       |\n",
    "| 4%‚Äì5%        | **Never drop**          | This is a real category            |\n",
    "| >5%          | Treat as major category | Keep, understand, encode properly  |\n",
    "\n",
    "**Applying This to education_level**\n",
    "\n",
    "* The `Other` category in the training dataset accounts for 4.49% of all observations ‚Äî roughly 1 in 20 data points.\n",
    "* A category this large cannot be discarded without introducing bias or removing meaningful structure from the data.\n",
    "* Because education_level contains a catch-all `Other` bucket that does not fit cleanly into an ordered hierarchy, ordinal encoding would create an artificial ranking and inject false relationships.\n",
    "\n",
    "**Final Decision**\n",
    "\n",
    "* Use One-Hot Encoding for education_level.\n",
    "* This preserves all information, avoids incorrect ordinal assumptions, and reflects real-world feature engineering practice."
   ],
   "id": "71c921dddfbff34b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Ordinal Encoding\n",
    "The dataset includes a categorical variable called grade_subgrade, which represents a lender‚Äôs internal credit risk tier assigned to each loan applicant. This system is inherently ordinal:\n",
    "\n",
    "* The letter grade (A‚ÄìG) indicates the overall credit quality, where A is the lowest-risk tier and G is the highest-risk tier.\n",
    "* The subgrade (1‚Äì5) provides a finer ranking within each grade, e.g., A1 is better than A5, and B1 is better than B5.\n",
    "\n",
    "Because both components follow a strict, meaningful order, they should not be one-hot encoded. Instead:\n",
    "\n",
    "1. Split the combined string (grade_subgrade) into two columns:\n",
    "    * `grade`: first character (A‚ÄìG)\n",
    "    * `subgrade`: numeric rating within that grade (1‚Äì5)\n",
    "\n",
    "2. Encode each component using ordinal encoding, preserving the lender‚Äôs risk hierarchy:\n",
    "    * `grade`: A=1, B=2, ‚Ä¶ G=7\n",
    "    * `subgrade`: already numeric, use directly as an ordered variable\n",
    "\n",
    "This approach maintains the underlying credit-risk structure and avoids losing valuable predictive signal."
   ],
   "id": "45a7940529fdce52"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T21:24:10.535444Z",
     "start_time": "2025-11-15T21:24:10.106485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Ordinal Encoding for grade_subgrade ---\n",
    "# This version is safe to run multiple times without KeyErrors.\n",
    "\n",
    "# Split only if column exists\n",
    "if 'grade_subgrade' in loan_train_df.columns:\n",
    "\n",
    "    # Extract grade (Letter) and subgrade (Digit)\n",
    "    loan_train_df['grade'] = loan_train_df['grade_subgrade'].str[0]\n",
    "    loan_train_df['subgrade'] = loan_train_df['grade_subgrade'].str[1].astype(int)\n",
    "\n",
    "    loan_test_df['grade'] = loan_test_df['grade_subgrade'].str[0]\n",
    "    loan_test_df['subgrade'] = loan_test_df['grade_subgrade'].str[1].astype(int)\n",
    "\n",
    "    # Drop the original combined column\n",
    "    loan_train_df = loan_train_df.drop(columns=['grade_subgrade'])\n",
    "    loan_test_df = loan_test_df.drop(columns=['grade_subgrade'])\n",
    "\n",
    "# Ordinal encoding mapping\n",
    "grade_mapping = {'A':1, 'B':2, 'C':3, 'D':4, 'E':5, 'F':6, 'G':7}\n",
    "\n",
    "# Map grade values (safe even if it already exists)\n",
    "loan_train_df['grade'] = loan_train_df['grade'].map(grade_mapping)\n",
    "loan_test_df['grade'] = loan_test_df['grade'].map(grade_mapping)\n",
    "\n",
    "# sanity print\n",
    "print(loan_train_df\n",
    "      [['grade', 'subgrade']].head())\n"
   ],
   "id": "a6cf99723cc0ed20",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   grade  subgrade\n",
      "0      3         3\n",
      "1      4         3\n",
      "2      3         5\n",
      "3      6         1\n",
      "4      4         1\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T21:26:13.619361Z",
     "start_time": "2025-11-15T21:26:12.651580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- One-Hot Encoding for categorical columns (SAFE VERSION) ---\n",
    "\n",
    "# Define categorical columns\n",
    "cat_cols = [\n",
    "    \"gender\",\n",
    "    \"marital_status\",\n",
    "    \"education_level\",\n",
    "    \"employment_status\",\n",
    "    \"loan_purpose\"\n",
    "]\n",
    "\n",
    "# Only attempt encoding if ALL columns exist\n",
    "missing_columns = [col for col in cat_cols if col not in loan_train_df.columns]\n",
    "if missing_columns:\n",
    "    raise KeyError(f\"The following categorical columns are missing and cannot be encoded: {missing_columns}\")\n",
    "\n",
    "# Combine for fitting (avoids mismatched categories)\n",
    "combined_cat_data = pd.concat([loan_train_df[cat_cols], loan_test_df[cat_cols]], axis=0)\n",
    "\n",
    "# Create encoder\n",
    "ohe = OneHotEncoder(\n",
    "    handle_unknown=\"ignore\",\n",
    "    sparse_output=False\n",
    ")\n",
    "\n",
    "# Fit on combined\n",
    "ohe.fit(combined_cat_data)\n",
    "\n",
    "# Transform train/test\n",
    "train_ohe = ohe.transform(loan_train_df[cat_cols])\n",
    "test_ohe = ohe.transform(loan_test_df[cat_cols])\n",
    "\n",
    "# OHE feature names\n",
    "ohe_cols = ohe.get_feature_names_out(cat_cols)\n",
    "\n",
    "# Convert to DataFrames (safe ‚Äî does not modify original)\n",
    "loan_train_ohe_df = pd.DataFrame(train_ohe, columns=ohe_cols, index=loan_train_df.index)\n",
    "loan_test_ohe_df = pd.DataFrame(test_ohe, columns=ohe_cols, index=loan_test_df.index)\n",
    "\n",
    "print(\"OHE encoding complete. Encoded DataFrame shapes:\")\n",
    "print(\"Train OHE:\", loan_train_ohe_df.shape)\n",
    "print(\"Test OHE:\", loan_test_ohe_df.shape)\n",
    "\n",
    "\n"
   ],
   "id": "a35e76327ca69a66",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OHE encoding complete. Encoded DataFrame shapes:\n",
      "Train OHE: (593994, 25)\n",
      "Test OHE: (254569, 25)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T21:31:02.604975Z",
     "start_time": "2025-11-15T21:31:02.234622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Final merge for encoded features (SAFE VERSION) ---\n",
    "\n",
    "# Make copies so originals are never modified\n",
    "train_tmp = loan_train_df.copy()\n",
    "test_tmp = loan_test_df.copy()\n",
    "\n",
    "# Drop original categorical columns ONLY if they exist\n",
    "train_tmp = train_tmp.drop(columns=[col for col in cat_cols if col in train_tmp.columns])\n",
    "test_tmp = test_tmp.drop(columns=[col for col in cat_cols if col in test_tmp.columns])\n",
    "\n",
    "# Drop grade_subgrade if still present (safe)\n",
    "for col in ['grade_subgrade']:\n",
    "    if col in train_tmp.columns:\n",
    "        train_tmp = train_tmp.drop(columns=[col])\n",
    "    if col in test_tmp.columns:\n",
    "        test_tmp = test_tmp.drop(columns=[col])\n",
    "\n",
    "# Add OHE features (does not overlap with existing columns)\n",
    "loan_train_encoded = pd.concat([train_tmp, loan_train_ohe_df], axis=1)\n",
    "loan_test_encoded = pd.concat([test_tmp, loan_test_ohe_df], axis=1)\n",
    "\n",
    "print(\"Train encoded shape:\", loan_train_encoded.shape)\n",
    "print(\"Test encoded shape:\", loan_test_encoded.shape)\n",
    "\n"
   ],
   "id": "b86f414736221a2d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train encoded shape: (593994, 34)\n",
      "Test encoded shape: (254569, 33)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T21:31:06.026730Z",
     "start_time": "2025-11-15T21:31:06.022328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Sanity check: Ensure matching features between train and test ---\n",
    "\n",
    "train_cols = set(loan_train_encoded.columns) - {\"loan_paid_back\"}  # remove target\n",
    "test_cols = set(loan_test_encoded.columns)\n",
    "\n",
    "if train_cols != test_cols:\n",
    "    extra_in_train = train_cols - test_cols\n",
    "    extra_in_test = test_cols - train_cols\n",
    "\n",
    "    raise AssertionError(\n",
    "        f\"ERROR: Train and Test columns do NOT match!\\n\"\n",
    "        f\"Columns only in TRAIN: {extra_in_train}\\n\"\n",
    "        f\"Columns only in TEST : {extra_in_test}\"\n",
    "    )\n",
    "\n",
    "print(\"Column alignment check passed ‚Äî train/test feature sets match.\")\n",
    "\n"
   ],
   "id": "4afadf75f41757ca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column alignment check passed ‚Äî train/test feature sets match.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ea266f5fd477e4b8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
